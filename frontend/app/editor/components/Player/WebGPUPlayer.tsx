/**
 * WebGPU Video Player Component
 * åŸºäº WebGPU çš„è§†é¢‘æ’­æ”¾å’Œåˆæˆå¼•æ“
 * å®Œå…¨ç‹¬ç«‹çš„æ’­æ”¾å™¨ï¼Œä¸ä¾èµ–å¤–éƒ¨çŠ¶æ€ç®¡ç†
 */

import {
  useImperativeHandle,
  useRef,
  useEffect,
  useState,
  useCallback,
  forwardRef,
} from "react";
import {
  PlayIcon,
  PauseIcon,
  PreviousFrameIcon,
  NextFrameIcon,
} from "../../icons";
import { Track } from "../../types/timeline";
import { convertFileSrc } from "@tauri-apps/api/core";
import { SHADER_EXTERNAL, SHADER_2D } from "./shader/unified";
import { formatTime } from "../../utils/time";
import { generateId } from "../../utils/timeline";
import { useTimelineStore } from "../../stores/timelineStore";
import { MediaSourceFactory } from "./media-sources";

/**
 * è§†é¢‘å›¾å±‚æ¥å£
 */
export interface VideoLayer {
  id: string;
  name: string;
  video: HTMLVideoElement;
  zIndex: number;
  posX: number;
  posY: number;
  scale: number;
  startTime: number;
  duration: number; // clip åœ¨æ—¶é—´è½´ä¸Šçš„æŒç»­æ—¶é—´
  baseScaleX: number;
  baseScaleY: number;
  uniformBuffer?: GPUBuffer;
  opacity?: number;
  rotation?: number;
  isImage?: boolean; // æ ‡è®°æ˜¯å¦ä¸ºå›¾ç‰‡ï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
  imageTexture?: GPUTexture; // å›¾ç‰‡çº¹ç†ç¼“å­˜
}

/**
 * Player æš´éœ²çš„æ–¹æ³•æ¥å£
 */
export interface PlayerRef {
  play: () => void;
  pause: () => void;
  togglePlayPause: () => void;
  seekTo: (time: number) => void;
  stepForward: () => void;
  stepBackward: () => void;
  getCurrentTime: () => number;
  getDuration: () => number;
  isPlaying: () => boolean;
  addVideoLayer: (
    videoSrc: string,
    startTime: number,
    name?: string,
  ) => Promise<void>;
  addImageLayer: (
    imageSrc: string,
    startTime: number,
    duration: number,
    name?: string,
    clipId?: string,
    transform?: {
      position?: { x: number; y: number };
      scale?: number;
      rotation?: number;
      opacity?: number;
    },
  ) => Promise<void>;
  clearLayers: () => void;
  updateLayerTransform: (
    layerId: string,
    transform: Partial<VideoLayer>,
  ) => void;
  updateClipTransform: (
    clipId: string,
    transform: {
      position?: { x: number; y: number };
      scale?: number;
      rotation?: number;
      opacity?: number;
    },
  ) => void;
  syncTracksToLayers: (tracks: Track[]) => Promise<void>;
}

/**
 * Player ç»„ä»¶å±æ€§
 */
interface PlayerProps {
  tracks: Track[];
  fps?: number; // å¸§ç‡ï¼Œç”¨äºä¸Šä¸€å¸§/ä¸‹ä¸€å¸§åŠŸèƒ½
  onTimeUpdate?: (currentTime: number) => void;
  onPlayStateChange?: (isPlaying: boolean) => void;
  onDurationChange?: (duration: number) => void;
}

export const WebGPUPlayer = forwardRef<PlayerRef, PlayerProps>(
  (
    {
      tracks,
      fps = 30,
      onTimeUpdate,
      onPlayStateChange,
      onDurationChange,
    }: PlayerProps,
    ref,
  ) => {
    // Canvas å¼•ç”¨
    const canvasRef = useRef<HTMLCanvasElement>(null);

    // æ’­æ”¾çŠ¶æ€ - ç»„ä»¶å†…éƒ¨çŠ¶æ€
    const [isPlaying, setIsPlaying] = useState(false);
    const [currentTime, setCurrentTime] = useState(0);
    const [duration, setDuration] = useState(0);
    const [hasLayers, setHasLayers] = useState(false);
    const [isWebGPUReady, setIsWebGPUReady] = useState(false);

    // ä½¿ç”¨ ref æ¥è·Ÿè¸ªä¸Šæ¬¡é€šçŸ¥çš„å€¼ï¼Œé¿å…é‡å¤é€šçŸ¥
    const lastNotifiedTimeRef = useRef<number>(currentTime);
    const lastNotifiedDurationRef = useRef<number>(duration);
    const lastNotifiedPlayStateRef = useRef<boolean>(isPlaying);

    // WebGPU èµ„æºå¼•ç”¨
    const deviceRef = useRef<GPUDevice | null>(null);
    const contextRef = useRef<GPUCanvasContext | null>(null);
    const pipelineRef = useRef<GPURenderPipeline | null>(null);
    const pipeline2DRef = useRef<GPURenderPipeline | null>(null);
    const samplerRef = useRef<GPUSampler | null>(null);

    // å›¾å±‚å’ŒåŠ¨ç”»çŠ¶æ€
    const layersRef = useRef<VideoLayer[]>([]);
    const animationFrameRef = useRef<number | null>(null);
    const lastTimestampRef = useRef<number>(0);
    const isSeekingRef = useRef(false);
    const isPlayingRef = useRef(isPlaying);
    const currentTimeRef = useRef(currentTime);
    const durationRef = useRef(duration);

    // ç”»å¸ƒå°ºå¯¸ - ä» stage è·å–
    const stage = useTimelineStore((state) => state.stage);
    const width: number = stage.width;
    const height: number = stage.height;

    /**
     * å°†åƒç´ åæ ‡è½¬æ¢ä¸º WebGPU æ ‡å‡†åŒ–åæ ‡
     * åƒç´ åæ ‡ç³»ï¼šä¸­å¿ƒä¸ºåŸç‚¹ (0, 0)ï¼Œå‘å³ä¸º X æ­£æ–¹å‘ï¼Œå‘ä¸Šä¸º Y æ­£æ–¹å‘
     * WebGPU åæ ‡ç³»ï¼šä¸­å¿ƒä¸ºåŸç‚¹ (0, 0)ï¼Œå‘å³ä¸º X æ­£æ–¹å‘ï¼Œå‘ä¸Šä¸º Y æ­£æ–¹å‘ï¼ŒèŒƒå›´ [-1, 1]
     */
    const pixelToNormalized = useCallback(
      (pixelX: number, pixelY: number): { x: number; y: number } => {
        // å°†åƒç´ å€¼è½¬æ¢ä¸ºæ ‡å‡†åŒ–åæ ‡
        const normalizedX = pixelX / (width / 2);
        const normalizedY = pixelY / (height / 2);
        return { x: normalizedX, y: normalizedY };
      },
      [width, height],
    );

    /**
     * å°† WebGPU æ ‡å‡†åŒ–åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
     * æš‚æ—¶æœªä½¿ç”¨ï¼Œä¿ç•™ä¾›å°†æ¥ä½¿ç”¨
     */
    // const normalizedToPixel = useCallback(
    //   (normalizedX: number, normalizedY: number): { x: number; y: number } => {
    //     const pixelX = normalizedX * (width / 2);
    //     const pixelY = normalizedY * (height / 2);
    //     return { x: pixelX, y: pixelY };
    //   },
    //   [width, height],
    // );

    /**
     * åˆå§‹åŒ– WebGPU
     */
    const initWebGPU = async () => {
      if (!navigator.gpu) {
        console.error("WebGPU ä¸æ”¯æŒ");
        return false;
      }

      try {
        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
          console.error("æ— æ³•è·å– GPU é€‚é…å™¨");
          return false;
        }

        const device = await adapter.requestDevice();
        deviceRef.current = device;

        const canvas = canvasRef.current;
        if (!canvas) return false;

        // è®¾ç½®ç”»å¸ƒå°ºå¯¸
        canvas.width = width;
        canvas.height = height;

        const context = canvas.getContext("webgpu");
        if (!context) {
          console.error("æ— æ³•è·å– WebGPU ä¸Šä¸‹æ–‡");
          return false;
        }

        contextRef.current = context;
        context.configure({
          device,
          format: navigator.gpu.getPreferredCanvasFormat(),
          alphaMode: "premultiplied",
        });

        // åˆ›å»º Shader æ¨¡å— (external texture for video)
        const shaderModule = device.createShaderModule({
          code: SHADER_EXTERNAL,
        });

        // åˆ›å»ºæ¸²æŸ“ç®¡çº¿ (external texture for video)
        const pipeline = device.createRenderPipeline({
          layout: "auto",
          vertex: {
            module: shaderModule,
            entryPoint: "vs_main",
          },
          fragment: {
            module: shaderModule,
            entryPoint: "fs_main",
            targets: [
              {
                format: navigator.gpu.getPreferredCanvasFormat(),
                blend: {
                  color: {
                    operation: "add",
                    srcFactor: "src-alpha",
                    dstFactor: "one-minus-src-alpha",
                  },
                  alpha: {
                    operation: "add",
                    srcFactor: "one",
                    dstFactor: "one-minus-src-alpha",
                  },
                },
              },
            ],
          },
          primitive: { topology: "triangle-strip" },
        });

        pipelineRef.current = pipeline;

        // åˆ›å»º Shader æ¨¡å— (2D texture for images)
        const shader2DModule = device.createShaderModule({ code: SHADER_2D });

        // åˆ›å»ºæ¸²æŸ“ç®¡çº¿ (2D texture for images)
        const pipeline2D = device.createRenderPipeline({
          layout: "auto",
          vertex: {
            module: shader2DModule,
            entryPoint: "vs_main",
          },
          fragment: {
            module: shader2DModule,
            entryPoint: "fs_main",
            targets: [
              {
                format: navigator.gpu.getPreferredCanvasFormat(),
                blend: {
                  color: {
                    operation: "add",
                    srcFactor: "src-alpha",
                    dstFactor: "one-minus-src-alpha",
                  },
                  alpha: {
                    operation: "add",
                    srcFactor: "one",
                    dstFactor: "one-minus-src-alpha",
                  },
                },
              },
            ],
          },
          primitive: { topology: "triangle-strip" },
        });

        pipeline2DRef.current = pipeline2D;

        // åˆ›å»ºé‡‡æ ·å™¨
        const sampler = device.createSampler({
          magFilter: "linear",
          minFilter: "linear",
        });

        samplerRef.current = sampler;

        setIsWebGPUReady(true);
        return true;
      } catch (error) {
        console.error("WebGPU åˆå§‹åŒ–å¤±è´¥:", error);
        setIsWebGPUReady(false);
        return false;
      }
    };

    /**
     * åŒæ­¥æ‰€æœ‰è§†é¢‘åˆ°æŒ‡å®šæ—¶é—´
     */
    const syncVideosToTime = useCallback((time: number) => {
      layersRef.current.forEach((layer) => {
        // è·³è¿‡å›¾ç‰‡å›¾å±‚ï¼Œå›¾ç‰‡ä¸éœ€è¦è§†é¢‘åŒæ­¥
        if (layer.isImage) return;

        const clipDuration = layer.duration || layer.video.duration;
        if (!clipDuration) return;

        const localTime = time - layer.startTime;
        const targetTime = Math.max(0, Math.min(localTime, clipDuration));

        if (
          Math.abs(layer.video.currentTime - targetTime) > 0.05 &&
          layer.video.readyState >= 2
        ) {
          layer.video.currentTime = targetTime;
        }
      });
    }, []);

    /**
     * æ¸²æŸ“å¾ªç¯ - ä½¿ç”¨ ref è·å–æœ€æ–°çŠ¶æ€
     */
    const renderLoopRef = useRef<((timestamp: number) => void) | null>(null);

    useEffect(() => {
      isPlayingRef.current = isPlaying;
      currentTimeRef.current = currentTime;
      durationRef.current = duration;

      const renderLoop = (timestamp: number) => {
        if (!lastTimestampRef.current) {
          lastTimestampRef.current = timestamp;
        }

        const deltaTime = (timestamp - lastTimestampRef.current) / 1000;
        lastTimestampRef.current = timestamp;

        const device = deviceRef.current;
        const context = contextRef.current;
        const pipeline = pipelineRef.current;
        const pipeline2D = pipeline2DRef.current;
        const sampler = samplerRef.current;

        if (!device || !context || !pipeline || !pipeline2D || !sampler) {
          animationFrameRef.current = requestAnimationFrame(renderLoop);
          return;
        }

        const currentIsPlaying = isPlayingRef.current;
        const currentDuration = durationRef.current;
        let newTime = currentTimeRef.current;

        // æ›´æ–°æ—¶é—´
        if (!isSeekingRef.current && currentIsPlaying) {
          newTime += deltaTime;

          if (newTime >= currentDuration) {
            newTime = currentDuration;
            // æ’­æ”¾ç»“æŸï¼Œæš‚åœ
            setIsPlaying(false);
            layersRef.current.forEach((layer) => layer.video.pause());
          }

          setCurrentTime(newTime);
        }

        // å¼€å§‹æ¸²æŸ“
        const commandEncoder = device.createCommandEncoder();
        const currentTexture = context.getCurrentTexture();
        const renderPass = commandEncoder.beginRenderPass({
          colorAttachments: [
            {
              view: currentTexture.createView(),
              clearValue: { r: 0.02, g: 0.02, b: 0.02, a: 1.0 },
              loadOp: "clear",
              storeOp: "store",
            },
          ],
        });

        // æŒ‰ zIndex æ’åºå›¾å±‚
        const sortedLayers = [...layersRef.current].sort(
          (a, b) => a.zIndex - b.zIndex,
        );

        for (const layer of sortedLayers) {
          const localTime = newTime - layer.startTime;

          // è°ƒè¯•ï¼šæ¯éš”ä¸€æ®µæ—¶é—´è¾“å‡ºå›¾å±‚çŠ¶æ€
          if (layer.isImage && Math.floor(newTime * 10) % 10 === 0) {
            console.log("ğŸ¬ æ¸²æŸ“å›¾å±‚:", {
              id: layer.id,
              name: layer.name,
              isImage: layer.isImage,
              localTime,
              duration: layer.duration,
              hasTexture: !!layer.imageTexture,
              currentTime: newTime,
              startTime: layer.startTime,
            });
          }

          // æ§åˆ¶è§†é¢‘æ’­æ”¾çŠ¶æ€ï¼ˆä»…å¯¹è§†é¢‘ï¼‰
          if (!layer.isImage) {
            if (currentIsPlaying && !isSeekingRef.current) {
              const videoClipDuration = layer.duration || layer.video.duration;
              if (localTime >= 0 && localTime < videoClipDuration) {
                if (layer.video.paused && !layer.video.ended) {
                  layer.video.play().catch(() => {});
                }
              } else {
                if (!layer.video.paused) {
                  layer.video.pause();
                }
              }
            }
          }

          // åˆ¤æ–­æ˜¯å¦å¯è§
          const clipDuration = layer.duration || layer.video.duration;
          const isVisible = localTime >= 0 && localTime <= clipDuration;

          // æ£€æŸ¥èµ„æºæ˜¯å¦å‡†å¤‡å¥½
          let hasResource = false;
          if (layer.isImage) {
            hasResource = !!layer.imageTexture;
            if (!hasResource && Math.floor(newTime * 10) % 10 === 0) {
              console.warn("âš ï¸ å›¾ç‰‡çº¹ç†æœªå°±ç»ª:", layer.name);
            }
          } else {
            hasResource = layer.video.readyState >= 2 && !layer.video.seeking;
          }

          if (
            !isVisible &&
            layer.isImage &&
            Math.floor(newTime * 10) % 10 === 0
          ) {
            console.log("ğŸ‘ï¸ å›¾ç‰‡ä¸å¯è§:", {
              name: layer.name,
              localTime,
              duration: layer.duration,
              isVisible,
            });
          }

          if (isVisible && hasResource) {
            try {
              // å°†åƒç´ åæ ‡è½¬æ¢ä¸ºæ ‡å‡†åŒ–åæ ‡
              const normalizedPos = pixelToNormalized(layer.posX, layer.posY);

              // æ›´æ–° uniform buffer
              const data = new Float32Array([
                normalizedPos.x,
                normalizedPos.y,
                layer.baseScaleX * layer.scale,
                layer.baseScaleY * layer.scale,
                layer.rotation ?? 0,
                layer.opacity ?? 1.0,
              ]);

              if (!layer.uniformBuffer) {
                layer.uniformBuffer = device.createBuffer({
                  size: 24,
                  usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
                });
              }

              device.queue.writeBuffer(layer.uniformBuffer, 0, data);

              // æ ¹æ®ç±»å‹é€‰æ‹©ç®¡çº¿å¹¶åˆ›å»º bind group
              let bindGroup: GPUBindGroup;

              if (layer.isImage && layer.imageTexture) {
                // å›¾ç‰‡ï¼šä½¿ç”¨ 2D çº¹ç†ç®¡çº¿
                if (Math.floor(newTime * 10) % 50 === 0) {
                  console.log("ğŸ¨ ä½¿ç”¨ 2D çº¹ç†ç®¡çº¿æ¸²æŸ“å›¾ç‰‡:", layer.name);
                }
                renderPass.setPipeline(pipeline2D);
                bindGroup = device.createBindGroup({
                  layout: pipeline2D.getBindGroupLayout(0),
                  entries: [
                    { binding: 0, resource: { buffer: layer.uniformBuffer } },
                    { binding: 1, resource: sampler },
                    {
                      binding: 2,
                      resource: layer.imageTexture.createView(),
                    },
                  ],
                });
              } else {
                // è§†é¢‘ï¼šä½¿ç”¨å¤–éƒ¨çº¹ç†ç®¡çº¿
                renderPass.setPipeline(pipeline);
                bindGroup = device.createBindGroup({
                  layout: pipeline.getBindGroupLayout(0),
                  entries: [
                    { binding: 0, resource: { buffer: layer.uniformBuffer } },
                    { binding: 1, resource: sampler },
                    {
                      binding: 2,
                      resource: device.importExternalTexture({
                        source: layer.video,
                      }),
                    },
                  ],
                });
              }

              renderPass.setBindGroup(0, bindGroup);
              renderPass.draw(4);
            } catch (error) {
              // æ¸²æŸ“é”™è¯¯
              console.error("âŒ æ¸²æŸ“é”™è¯¯:", {
                layer: layer.name,
                isImage: layer.isImage,
                error,
              });
            }
          }
        }

        renderPass.end();
        device.queue.submit([commandEncoder.finish()]);

        animationFrameRef.current = requestAnimationFrame(renderLoop);
      };

      renderLoopRef.current = renderLoop;
    }, [isPlaying, currentTime, duration, pixelToNormalized]);

    /**
     * æ›´æ–°æ€»æ—¶é•¿ï¼ˆæ ¹æ®æ‰€æœ‰å›¾å±‚çš„æœ€å¤§ç»“æŸæ—¶é—´ï¼‰
     */
    const updateDuration = useCallback(() => {
      const maxDuration =
        layersRef.current.length === 0
          ? 0
          : Math.max(
              ...layersRef.current.map(
                (l) => l.startTime + (l.duration || l.video.duration || 0),
              ),
            );

      setDuration((prevDuration) => {
        if (Math.abs(prevDuration - maxDuration) > 0.001) {
          return maxDuration;
        }
        return prevDuration;
      });
    }, []);

    /**
     * æ·»åŠ è§†é¢‘å›¾å±‚
     */
    const addVideoLayer = useCallback(
      async (
        videoSrc: string,
        startTime: number = 0,
        name?: string,
        clipId?: string,
        transform?: {
          position?: { x: number; y: number };
          scale?: number;
          rotation?: number;
          opacity?: number;
        },
      ): Promise<void> => {
        const device = deviceRef.current;
        if (!device) {
          console.error("WebGPU æœªåˆå§‹åŒ–");
          return;
        }

        return new Promise((resolve, reject) => {
          const video = document.createElement("video");
          video.src = videoSrc;
          video.muted = false;
          video.playsInline = true;
          video.crossOrigin = "anonymous";
          video.preload = "auto";

          video.onloadedmetadata = () => {
            const canvasAspect = width / height;
            const videoAspect = video.videoWidth / video.videoHeight;

            let initScaleX = 1.0;
            let initScaleY = 1.0;

            // è‡ªé€‚åº”ç¼©æ”¾ä»¥é€‚é…ç”»å¸ƒ
            if (videoAspect > canvasAspect) {
              initScaleY = canvasAspect / videoAspect;
            } else {
              initScaleX = videoAspect / canvasAspect;
            }

            const layer: VideoLayer = {
              id: clipId ?? generateId(),
              name: name || `Video ${layersRef.current.length + 1}`,
              video,
              zIndex: 100 - layersRef.current.length,
              // é»˜è®¤ä½ç½®ä¸ºä¸­å¿ƒ (0, 0) - ç¬›å¡å°”åæ ‡ç³»
              posX: transform?.position?.x ?? 0,
              posY: transform?.position?.y ?? 0,
              scale: transform?.scale ?? 1.0,
              startTime,
              duration: video.duration,
              baseScaleX: initScaleX,
              baseScaleY: initScaleY,
              opacity: transform?.opacity ?? 1.0,
              rotation: transform?.rotation
                ? transform.rotation * (Math.PI / 180)
                : 0,
              isImage: false,
            };

            layersRef.current.push(layer);
            setHasLayers(true);
            updateDuration();
            resolve();
          };

          video.onerror = () => {
            reject(new Error("è§†é¢‘åŠ è½½å¤±è´¥"));
          };
        });
      },
      [updateDuration, width, height],
    );

    /**
     * æ·»åŠ å›¾ç‰‡å›¾å±‚
     */
    const addImageLayer = useCallback(
      async (
        imageSrc: string,
        startTime: number = 0,
        duration: number = 5,
        name?: string,
        clipId?: string,
        transform?: {
          position?: { x: number; y: number };
          scale?: number;
          rotation?: number;
          opacity?: number;
        },
      ): Promise<void> => {
        const device = deviceRef.current;
        if (!device) {
          console.error("WebGPU æœªåˆå§‹åŒ–");
          return;
        }

        console.log("ğŸ–¼ï¸ å¼€å§‹åŠ è½½å›¾ç‰‡:", imageSrc);

        try {
          // ä½¿ç”¨ MediaSourceFactory åŠ è½½å›¾ç‰‡
          const layerId = clipId ?? generateId();
          console.log("ğŸ“ åˆ›å»ºå›¾å±‚ ID:", layerId);

          const source = await MediaSourceFactory.createAndLoad(
            layerId,
            imageSrc,
          );

          console.log("âœ… å›¾ç‰‡åŠ è½½æˆåŠŸ:", {
            type: source.type,
            width: source.width,
            height: source.height,
            duration: source.duration,
          });

          // è®¡ç®—åŸºç¡€ç¼©æ”¾
          const canvasAspect = width / height;
          const imageAspect = source.width / source.height;

          let initScaleX = 1.0;
          let initScaleY = 1.0;

          if (imageAspect > canvasAspect) {
            initScaleY = canvasAspect / imageAspect;
          } else {
            initScaleX = imageAspect / canvasAspect;
          }

          console.log("ğŸ“ è®¡ç®—ç¼©æ”¾:", { initScaleX, initScaleY });

          // è·å–çº¹ç†å¹¶ç¼“å­˜
          const textureResult = source.getTexture(device, 0);
          if (!textureResult || textureResult.type !== "2d") {
            throw new Error("æ— æ³•è·å–å›¾ç‰‡çº¹ç†");
          }

          console.log("ğŸ¨ çº¹ç†åˆ›å»ºæˆåŠŸ:", textureResult.type);

          // åˆ›å»ºä¸€ä¸ªå‡çš„ video å…ƒç´ ç”¨äºå…¼å®¹ç°æœ‰æ¸²æŸ“é€»è¾‘
          const dummyVideo = document.createElement("video");
          dummyVideo.width = source.width;
          dummyVideo.height = source.height;

          const layer: VideoLayer = {
            id: layerId,
            name: name || `Image ${layersRef.current.length + 1}`,
            video: dummyVideo,
            zIndex: 100 - layersRef.current.length,
            posX: transform?.position?.x ?? 0,
            posY: transform?.position?.y ?? 0,
            scale: transform?.scale ?? 1.0,
            startTime,
            duration: duration,
            baseScaleX: initScaleX,
            baseScaleY: initScaleY,
            opacity: transform?.opacity ?? 1.0,
            rotation: transform?.rotation
              ? transform.rotation * (Math.PI / 180)
              : 0,
            isImage: true,
            imageTexture: textureResult.texture as GPUTexture,
          };

          layersRef.current.push(layer);
          setHasLayers(true);
          updateDuration();

          console.log("ğŸ‰ å›¾ç‰‡å›¾å±‚æ·»åŠ æˆåŠŸ:", {
            id: layerId,
            name: layer.name,
            startTime,
            duration,
            layerCount: layersRef.current.length,
          });
        } catch (error) {
          console.error("âŒ å›¾ç‰‡åŠ è½½å¤±è´¥:", error);
          throw error;
        }
      },
      [updateDuration, width, height],
    );

    /**
     * æ¸…ç©ºæ‰€æœ‰å›¾å±‚
     */
    const clearLayers = useCallback(() => {
      layersRef.current.forEach((layer) => {
        if (!layer.isImage) {
          layer.video.pause();
          layer.video.src = "";
        }
        if (layer.imageTexture) {
          layer.imageTexture.destroy();
        }
        if (layer.uniformBuffer) {
          layer.uniformBuffer.destroy();
        }
      });
      layersRef.current = [];
      setHasLayers(false);
      setCurrentTime(0);
      updateDuration();
    }, [updateDuration]);

    /**
     * æ›´æ–°å›¾å±‚å˜æ¢
     */
    const updateLayerTransform = useCallback(
      (layerId: string, transform: Partial<VideoLayer>) => {
        const layer = layersRef.current.find((l) => l.id === layerId);
        if (layer) {
          Object.assign(layer, transform);
        }
      },
      [],
    );

    /**
     * ä» Timeline tracks åŒæ­¥è§†é¢‘å›¾å±‚
     */
    const syncTracksToLayers = useCallback(
      async (newTracks: Track[]) => {
        const device = deviceRef.current;
        if (!device || !isWebGPUReady) {
          console.warn("WebGPU æœªå°±ç»ªï¼Œç­‰å¾…åˆå§‹åŒ–...");
          return;
        }

        // æ”¶é›†æ‰€æœ‰è§†é¢‘å’Œå›¾ç‰‡ clips
        const mediaClips = newTracks.flatMap((track) =>
          track.clips
            .filter(
              (clip) =>
                (clip.type === "video" || clip.type === "image") &&
                clip.resourceSrc,
            )
            .map((clip) => ({
              id: clip.id,
              type: clip.type,
              src: clip.resourceSrc!,
              startTime: clip.startTime,
              duration: clip.duration,
              name: clip.name,
              transform: {
                position: clip.position,
                scale: clip.scale,
                rotation: clip.rotation,
                opacity: clip.opacity,
              },
            })),
        );

        // æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–° - ä¸ä»…æ£€æŸ¥ IDï¼Œè¿˜è¦æ£€æŸ¥ startTime ç­‰å±æ€§
        const existingIds = new Set(layersRef.current.map((l) => l.id));
        const newIds = new Set(mediaClips.map((c) => c.id));

        // æ£€æŸ¥æ˜¯å¦æœ‰ ID å˜åŒ–æˆ– startTime å˜åŒ–
        let needsUpdate =
          existingIds.size !== newIds.size ||
          ![...existingIds].every((id) => newIds.has(id));

        // å¦‚æœ ID ç›¸åŒï¼Œæ£€æŸ¥ startTime æ˜¯å¦æœ‰å˜åŒ–
        if (!needsUpdate) {
          for (const clip of mediaClips) {
            const layer = layersRef.current.find((l) => l.id === clip.id);
            if (layer && Math.abs(layer.startTime - clip.startTime) > 0.001) {
              needsUpdate = true;
              break;
            }
          }
        }

        if (!needsUpdate) {
          return;
        }

        // æ¸…ç©ºç°æœ‰å›¾å±‚
        layersRef.current.forEach((layer) => {
          if (!layer.isImage) {
            layer.video.pause();
            layer.video.src = "";
          }
          if (layer.imageTexture) {
            layer.imageTexture.destroy();
          }
          if (layer.uniformBuffer) {
            layer.uniformBuffer.destroy();
          }
        });
        layersRef.current = [];

        // æ·»åŠ æ–°å›¾å±‚
        for (const clip of mediaClips) {
          try {
            const mediaUrl = convertFileSrc(clip.src);

            if (clip.type === "video") {
              console.log("ğŸ¬ æ·»åŠ è§†é¢‘ clip:", clip.name);
              await addVideoLayer(
                mediaUrl,
                clip.startTime,
                clip.name,
                clip.id,
                clip.transform,
              );
            } else if (clip.type === "image") {
              console.log("ğŸ–¼ï¸ æ·»åŠ å›¾ç‰‡ clip:", {
                name: clip.name,
                src: mediaUrl,
                startTime: clip.startTime,
                duration: clip.duration,
              });
              await addImageLayer(
                mediaUrl,
                clip.startTime,
                clip.duration,
                clip.name,
                clip.id,
                clip.transform,
              );
            }
          } catch (error) {
            console.error(`åŠ è½½åª’ä½“å¤±è´¥: ${clip.name}`, error);
          }
        }

        setHasLayers(mediaClips.length > 0);

        // æ›´æ–°æ€»æ—¶é•¿
        updateDuration();
      },
      [addVideoLayer, addImageLayer, isWebGPUReady, updateDuration],
    );

    /**
     * æ’­æ”¾
     */
    const play = useCallback(() => {
      if (layersRef.current.length === 0) return;

      // å¦‚æœæ’­æ”¾åˆ°ç»“å°¾ï¼Œé‡ç½®åˆ°å¼€å§‹
      setCurrentTime((prevTime) => {
        if (prevTime >= duration - 0.001) {
          const newTime = 0;
          syncVideosToTime(newTime);
          return newTime;
        }
        return prevTime;
      });

      setIsPlaying(true);

      // å¯åŠ¨ç›¸å…³æ—¶é—´ç‚¹çš„è§†é¢‘
      layersRef.current.forEach((layer) => {
        // è·³è¿‡å›¾ç‰‡å›¾å±‚ï¼Œå›¾ç‰‡ä¸éœ€è¦æ’­æ”¾
        if (layer.isImage) return;

        const localTime = currentTime - layer.startTime;
        const clipDuration = layer.duration || layer.video.duration;
        if (localTime >= 0 && localTime < clipDuration) {
          layer.video.play().catch(() => {});
        }
      });
    }, [currentTime, duration, syncVideosToTime]);

    /**
     * æš‚åœ
     */
    const pause = useCallback(() => {
      setIsPlaying(false);
      layersRef.current.forEach((layer) => layer.video.pause());
    }, []);

    /**
     * åˆ‡æ¢æ’­æ”¾/æš‚åœ
     */
    const togglePlayPause = useCallback(() => {
      if (isPlaying) {
        pause();
      } else {
        play();
      }
    }, [isPlaying, play, pause]);

    /**
     * è·³è½¬åˆ°æŒ‡å®šæ—¶é—´
     */
    const seekTo = useCallback(
      (time: number) => {
        isSeekingRef.current = true;
        const clampedTime = Math.max(0, Math.min(time, duration));
        setCurrentTime(clampedTime);
        syncVideosToTime(clampedTime);

        setTimeout(() => {
          isSeekingRef.current = false;
        }, 100);
      },
      [duration, syncVideosToTime],
    );

    /**
     * ä¸‹ä¸€å¸§
     */
    const stepForward = useCallback(() => {
      const frameTime = 1 / fps;
      setCurrentTime((prevTime) => {
        const newTime = Math.min(prevTime + frameTime, duration);
        syncVideosToTime(newTime);
        return newTime;
      });
    }, [fps, duration, syncVideosToTime]);

    /**
     * ä¸Šä¸€å¸§
     */
    const stepBackward = useCallback(() => {
      const frameTime = 1 / fps;
      setCurrentTime((prevTime) => {
        const newTime = Math.max(prevTime - frameTime, 0);
        syncVideosToTime(newTime);
        return newTime;
      });
    }, [fps, syncVideosToTime]);

    /**
     * è·å–å½“å‰æ—¶é—´
     */
    const getCurrentTime = useCallback(() => currentTime, [currentTime]);

    /**
     * è·å–æ€»æ—¶é•¿
     */
    const getDuration = useCallback(() => duration, [duration]);

    /**
     * è·å–æ’­æ”¾çŠ¶æ€
     */
    const getIsPlaying = useCallback(() => isPlaying, [isPlaying]);

    // æš´éœ²æ–¹æ³•ç»™çˆ¶ç»„ä»¶
    useImperativeHandle(
      ref,
      () => ({
        play, // æ’­æ”¾
        pause, // æš‚åœ
        togglePlayPause, // åˆ‡æ¢æ’­æ”¾çŠ¶æ€
        seekTo, // è·³è½¬åˆ°æŒ‡å®šæ—¶é—´
        stepForward, // å‘å‰è·³ä¸€å¸§
        stepBackward, // å‘åè·³ä¸€å¸§
        getCurrentTime, // è·å–å½“å‰æ—¶é—´
        getDuration, // è·å–æ€»æ—¶é•¿
        isPlaying: getIsPlaying, // è·å–æ’­æ”¾çŠ¶æ€
        addVideoLayer, // æ·»åŠ è§†é¢‘å±‚
        addImageLayer, // æ·»åŠ å›¾ç‰‡å±‚
        clearLayers, // æ¸…é™¤æ‰€æœ‰å±‚
        updateLayerTransform, // æ›´æ–°å±‚çš„å˜æ¢
        updateClipTransform: (
          clipId: string,
          transform: {
            position?: { x: number; y: number };
            scale?: number;
            rotation?: number;
            opacity?: number;
          },
        ) => {
          const layer = layersRef.current.find((l) => l.id === clipId);
          if (!layer) {
            console.warn(`Layer not found: ${clipId}`);
            return;
          }

          if (transform.position !== undefined) {
            layer.posX = transform.position.x;
            layer.posY = transform.position.y;
          }
          if (transform.scale !== undefined) {
            layer.scale = transform.scale;
          }
          if (transform.rotation !== undefined) {
            layer.rotation = transform.rotation * (Math.PI / 180);
          }
          if (transform.opacity !== undefined) {
            layer.opacity = transform.opacity;
          }
        },
        syncTracksToLayers, // åŒæ­¥è½¨é“åˆ°å±‚
      }),
      [
        play,
        pause,
        togglePlayPause,
        seekTo,
        stepForward,
        stepBackward,
        getCurrentTime,
        getDuration,
        getIsPlaying,
        addVideoLayer,
        addImageLayer,
        clearLayers,
        updateLayerTransform,
        syncTracksToLayers,
      ],
    );

    // åˆå§‹åŒ– WebGPU å’Œæ¸²æŸ“å¾ªç¯
    useEffect(() => {
      let mounted = true;
      const init = async () => {
        const success = await initWebGPU();
        if (success && mounted && renderLoopRef.current) {
          animationFrameRef.current = requestAnimationFrame(
            renderLoopRef.current,
          );
        }
      };

      init();

      return () => {
        mounted = false;
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
        }
        // æ¸…ç†å›¾å±‚
        layersRef.current.forEach((layer) => {
          layer.video.pause();
          layer.video.src = "";
          if (layer.uniformBuffer) {
            layer.uniformBuffer.destroy();
          }
        });
        layersRef.current = [];
      };
      // eslint-disable-next-line react-hooks/exhaustive-deps
    }, []);

    // ä» tracks åŒæ­¥å›¾å±‚ï¼ˆç­‰å¾… WebGPU åˆå§‹åŒ–å®Œæˆï¼‰
    // ä½¿ç”¨ useEffect å¼‚æ­¥é€šçŸ¥çˆ¶ç»„ä»¶çŠ¶æ€å˜åŒ–
    useEffect(() => {
      if (Math.abs(currentTime - lastNotifiedTimeRef.current) > 0.001) {
        lastNotifiedTimeRef.current = currentTime;
        onTimeUpdate?.(currentTime);
      }
    }, [currentTime, onTimeUpdate]);

    useEffect(() => {
      if (Math.abs(duration - lastNotifiedDurationRef.current) > 0.001) {
        lastNotifiedDurationRef.current = duration;
        onDurationChange?.(duration);
      }
    }, [duration, onDurationChange]);

    useEffect(() => {
      if (isPlaying !== lastNotifiedPlayStateRef.current) {
        lastNotifiedPlayStateRef.current = isPlaying;
        onPlayStateChange?.(isPlaying);
      }
    }, [isPlaying, onPlayStateChange]);

    useEffect(() => {
      let mounted = true;
      const sync = async () => {
        if (mounted && isWebGPUReady && tracks && tracks.length > 0) {
          await syncTracksToLayers(tracks);
        }
      };
      sync();
      return () => {
        mounted = false;
      };
    }, [tracks, syncTracksToLayers, isWebGPUReady]);

    // UI æ§åˆ¶å¤„ç†
    const handlePlayPause = () => {
      togglePlayPause();
    };

    const handlePrevious = () => {
      stepBackward();
    };

    const handleNext = () => {
      stepForward();
    };

    return (
      <main className={"flex-1 flex flex-col relative min-w-0 bg-editor-bg"}>
        {/* æ’­æ”¾å™¨ç”»å¸ƒ */}
        <div className="flex-1 flex items-center justify-center p-2">
          <canvas
            ref={canvasRef}
            className="aspect-video max-w-full max-h-full shadow-lg border border-editor-border bg-black object-contain"
          />
        </div>

        {/* æ’­æ”¾æ§åˆ¶æ  */}
        <div className="h-8 flex items-center justify-center gap-4 shrink-0 border-t border-editor-border bg-editor-bg">
          <button
            onClick={handlePrevious}
            className="transition-colors text-lg text-text-secondary hover:text-text-fg disabled:opacity-50 disabled:cursor-not-allowed"
            aria-label="ä¸Šä¸€å¸§"
            disabled={!hasLayers}
          >
            <PreviousFrameIcon size={20} />
          </button>

          <button
            onClick={handlePlayPause}
            className="transition-colors text-lg text-text-secondary hover:text-text-fg disabled:opacity-50 disabled:cursor-not-allowed"
            aria-label={isPlaying ? "æš‚åœ" : "æ’­æ”¾"}
            disabled={!hasLayers}
          >
            {isPlaying ? <PauseIcon size={20} /> : <PlayIcon size={20} />}
          </button>

          <button
            onClick={handleNext}
            className="transition-colors text-lg text-text-secondary hover:text-text-fg disabled:opacity-50 disabled:cursor-not-allowed"
            aria-label="ä¸‹ä¸€å¸§"
            disabled={!hasLayers}
          >
            <NextFrameIcon size={20} />
          </button>

          <div className="text-xs font-mono ml-4 text-accent-cyan">
            {formatTime(currentTime)} / {formatTime(duration)}
          </div>
        </div>
      </main>
    );
  },
);

WebGPUPlayer.displayName = "WebGPUPlayer";
